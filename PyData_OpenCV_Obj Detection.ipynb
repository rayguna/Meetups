{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Recognition Demonstration Using Out-of-the-Box Pre-Trained Models\n",
    "<br>\n",
    "*Abstract*  \n",
    " <div class='text-justify'>\n",
    "Here, I demonstrate object recognition of arbitrary objects using out-of-the-box pre-trained models. I use OpenCV library for the image processing and Keras library for the object recognition. I supply the unlabeled object to the program either as a saved image or as an image cropped from a live video. The program then processes the image using the built-in pre-trained models (VGG16, VGG19, InceptionV3, Xception, or ResNet50 ) in the Keras library. I will briefly explain what is happening under the hood. Finally, I provide resources for further study.  \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "#### I. OpenCV (10 min)\n",
    "1. Stream live video   \n",
    "2. Crop and save image from live video\n",
    "\n",
    "#### II. Object Recognition (35 min)\n",
    "A. Implementation (20 min)\n",
    "1. Define a function for implementing out-of-the-box-pre-trained models    \n",
    "2. Define a function for cropping an image from a live video and feeding the image into a selected pre-trained model \n",
    "3. The GUI Interface\n",
    "4. What else can we do with out-of-the-box pre-trained models?\n",
    "\n",
    "B. What is happening under the hood? (15 min)\n",
    "1. Imagenet: The origin of the pre-trained models  \n",
    "2. Pre-trained model architecture\n",
    "3. Pre-trained models comparison  \n",
    "4. Artificial intelligence - the big picture\n",
    "\n",
    "#### III. Resources for Further Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Streaming a live video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#call VideoCapture method\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, frame=cap.read()\n",
    "    \n",
    "    cv2.imshow('video',frame)\n",
    "\n",
    "    #press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF== ord('q'):\n",
    "        break  \n",
    "\n",
    "#When everything is done, release the capture and destroy window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "2. Crop and save image from live video\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#initialize image counter\n",
    "img_counter=0\n",
    "\n",
    "#activate webcam and read region of interest.\n",
    "while(True):\n",
    "    ret, frame=cap.read()\n",
    "    \n",
    "    #define rectangular region of interest (roi) for cropping: w=width, h=height\n",
    "    x=0; y=0; w=224; h=224;\n",
    "    cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    #read pixel arrays within the defined rectangle and call it roi\n",
    "    roi = frame[y:y+h, x:x+w]\n",
    "    \n",
    "    #when space button is pressed, take a picture and process image within roi\n",
    "    #https://stackoverflow.com/questions/34588464/python-how-to-capture-image-from-webcam-on-click-using-opencv/34588758\n",
    "    #https://stackoverflow.com/questions/14494101/using-other-keys-for-the-waitkey-function-of-opencv\n",
    "    if cv2.waitKey(33) == 32:\n",
    "        # SPACE pressed\n",
    "        #define image filename\n",
    "        #img_name = \"object_in_roi_{}.png\".format(img_counter)\n",
    "        \n",
    "        #save image\n",
    "        #cv2.imwrite(img_name, frame)\n",
    "        \n",
    "        #indicate filename of written image\n",
    "        #print(\"{} written!\".format(img_name))\n",
    "        \n",
    "        #increment img_counter\n",
    "        #img_counter += 1\n",
    "        \n",
    "        #add a text on cropped image\n",
    "        myStr='Hello World!'        \n",
    "        cv2.putText(roi, myStr, (10,20),1,1,(50,50,50),2)\n",
    "\n",
    "        #display text on cropped image\n",
    "        cv2.imshow('Object',roi)\n",
    "                        \n",
    "    #display original size image\n",
    "    cv2.imshow('video',frame)\n",
    "        \n",
    "    #press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF== ord('q'):\n",
    "        break  \n",
    "\n",
    "# When everything done, release the capture and destroy window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Object Recognition (35 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define a function for implementing out-of-the-box pre-trained models  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#dynamically set tensorflow backend\n",
    "#https://stackoverflow.com/questions/49121112/how-do-i-set-the-keras-backend-in-python-dynamically-when-loaded-using-superviso\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "#https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "#VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "#ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.resnet50 import decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "#InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications.inception_v3 import decode_predictions\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "#Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.applications.xception import decode_predictions\n",
    "from keras.applications.xception import Xception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code is copied fully from: https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/\n",
    "\n",
    "def pyimagesearch(model,image_array):\n",
    "    '''\n",
    "    Feed image_array into specified pre-trained model and return five best predictions.\n",
    "\n",
    "        inputs\n",
    "            model: vgg16, vgg19, inception, xception, or resnet \n",
    "\n",
    "            image: specify an image\n",
    "            \n",
    "        return\n",
    "            five best predicted objects and the corresponding probabilities\n",
    "    '''\n",
    "\n",
    "    #pyimagesearch\n",
    "    # define a dictionary that maps model names to their classes\n",
    "    # inside Keras\n",
    "    MODELS = {\n",
    "        \"vgg16\": VGG16,\n",
    "        \"vgg19\": VGG19,\n",
    "        \"inception\": InceptionV3,\n",
    "        \"xception\": Xception, # TensorFlow ONLY\n",
    "        \"resnet\": ResNet50\n",
    "    }\n",
    "\n",
    "    # ensure a valid model name was supplied via command line argument\n",
    "    if model not in MODELS.keys():\n",
    "        raise AssertionError(\"The --model command line argument should \"\n",
    "            \"be a key in the `MODELS` dictionary\")\n",
    "\n",
    "    # initialize the input image shape (224x224 pixels) along with\n",
    "    # the pre-processing function (this might need to be changed\n",
    "    # based on which model we use to classify our image)\n",
    "    inputShape = (224, 224)\n",
    "    preprocess = imagenet_utils.preprocess_input\n",
    "\n",
    "    # if we are using the InceptionV3 or Xception networks, then we\n",
    "    # need to set the input shape to (299x299) [rather than (224x224)]\n",
    "    # and use a different image processing function\n",
    "    if model in (\"inception\", \"xception\"):\n",
    "        inputShape = (299, 299)\n",
    "        preprocess = preprocess_input\n",
    "\n",
    "    # load our the network weights from disk (NOTE: if this is the\n",
    "    # first time you are running this script for a given network, the\n",
    "    # weights will need to be downloaded first -- depending on which\n",
    "    # network you are using, the weights can be 90-575MB, so be\n",
    "    # patient; the weights will be cached and subsequent runs of this\n",
    "    # script will be *much* faster)\n",
    "    print(\"[INFO] loading {}...\".format(model))\n",
    "    Network = MODELS[model]\n",
    "    model = Network(weights=\"imagenet\")\n",
    "\n",
    "    # load the input image using the Keras helper utility while ensuring\n",
    "    # the image is resized to `inputShape`, the required input dimensions\n",
    "    # for the ImageNet pre-trained network\n",
    "    print(\"[INFO] loading and pre-processing image...\")\n",
    "    #image = load_img(args[\"image\"], target_size=inputShape)\n",
    "    #image = img_to_array(image)\n",
    "    image=image_array\n",
    "    \n",
    "    # our input image is now represented as a NumPy array of shape\n",
    "    # (inputShape[0], inputShape[1], 3) however we need to expand the\n",
    "    # dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n",
    "    # so we can pass it through the network\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # pre-process the image using the appropriate function based on the\n",
    "    # model that has been loaded (i.e., mean subtraction, scaling, etc.)\n",
    "    image = preprocess(image)\n",
    "\n",
    "    # classify the image\n",
    "    print(\"[INFO] classifying image with '{}'...\".format(model))\n",
    "    preds = model.predict(image)\n",
    "    P = imagenet_utils.decode_predictions(preds)\n",
    "\n",
    "    myStr='' #a string variable to concat the five best predictions into a single string\n",
    "    \n",
    "    # loop over the predictions and display the rank-5 predictions +\n",
    "    # probabilities to our terminal\n",
    "    for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
    "        myStr+=\"{}. {}: {:.2f}% \\n\".format(i + 1, label, prob * 100)\n",
    "    \n",
    "    return myStr #this function returns a single string of the five best predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> 2. Define a function for cropping an image from a live video and feeding the image into a selected pre-trained model  </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def get_image_from_Video(specify_model):\n",
    "    '''\n",
    "    Stream live video and crop an image within the box when user presses space. \n",
    "    Feed image into a specified pre-trained model and return the five best predictions.\n",
    "    \n",
    "    input\n",
    "        cropped image from a live video\n",
    "    \n",
    "    return\n",
    "        five best predicted objects and the corresponding probabilities\n",
    "    '''\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    #initialize image counter\n",
    "    img_counter=0\n",
    "\n",
    "    #activate webcam and read region of interest.\n",
    "    while(True):\n",
    "        ret, frame=cap.read()\n",
    "\n",
    "        #define region of interest (roi): w=width, h=height\n",
    "        x=0; y=0; w=224; h=224;\n",
    "\n",
    "        #draw a rectangle\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        #read pixel arrays and call it roi\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        #initialize myStr\n",
    "        myStr=' '\n",
    "\n",
    "        #when space is pressed, take a picture and process image within roi\n",
    "        #https://stackoverflow.com/questions/34588464/python-how-to-capture-image-from-webcam-on-click-using-opencv/34588758\n",
    "        #https://stackoverflow.com/questions/14494101/using-other-keys-for-the-waitkey-function-of-opencv\n",
    "        if cv2.waitKey(33) == 32:#ord('a'):\n",
    "            \n",
    "            #feed image within roi into a selected pre-trained model by calling the function pyimagesearch\n",
    "            #display prediction as a text\n",
    "            myStr=pyimagesearch(specify_model,img_to_array(roi)) \n",
    "            \n",
    "            #indicate object name and probability on the image called roi\n",
    "            #https://stackoverflow.com/questions/27647424/opencv-puttext-new-line-character\n",
    "            #cv2.putText(roi, myStr, (10,20),1,1,(50,50,50),2)\n",
    "\n",
    "            y0, dy = 15, 15 #yo is the initial y offset and dy is the subsequent offset\n",
    "            for i, line in enumerate(myStr.split('\\n')):\n",
    "                y = y0 + i*dy\n",
    "                cv2.putText(roi, line, (0, y ), 1, 1, 2)\n",
    "\n",
    "            #display image with text\n",
    "            cv2.imshow('Object',roi)\n",
    "\n",
    "            #print object name\n",
    "            print(myStr)            \n",
    "            \n",
    "        #display original size image\n",
    "        cv2.imshow('video',frame)\n",
    "\n",
    "        #press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF== ord('q'):\n",
    "            break  \n",
    "\n",
    "    # When everything done, release the capture and destroy window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> 3. The GUI Interface </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.python-course.eu/tkinter_radiobuttons.php\n",
    "import tkinter as tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "root = tk.Tk()\n",
    "rdbValue = tk.IntVar()\n",
    "\n",
    "#call this function if Start button is triggered\n",
    "def pressed_Start():\n",
    "    \n",
    "    # initialize the input image shape (224x224 pixels) along with\n",
    "    # the pre-processing function (this might need to be changed\n",
    "    # based on which model we use to classify our image)\n",
    "    inputShape = (224, 224)\n",
    "    preprocess = imagenet_utils.preprocess_input\n",
    "\n",
    "    # if we are using the InceptionV3 or Xception networks, then we\n",
    "    # need to set the input shape to (299x299) [rather than (224x224)]\n",
    "    # and use a different image processing function\n",
    "    if optValue.get() in (\"inception\", \"xception\"):\n",
    "        inputShape = (299, 299)\n",
    "        preprocess = preprocess_input\n",
    "    \n",
    "    \n",
    "    #open up FileDialog window if picture is selected as the image source\n",
    "    ##https://stackoverflow.com/questions/9239514/filedialog-tkinter-and-opening-files\n",
    "    if str(rdbValue.get())==\"0\":\n",
    "        fname = askopenfilename(filetypes=((\"JPG\", \"*.jpeg\"),\n",
    "                                           (\"All files\", \"*.*\") ))\n",
    "        if fname:\n",
    "            try:               \n",
    "\n",
    "                #1. Load image and convert image to array. This image format will be used as input for object prediction.\n",
    "                image = load_img(fname, target_size=inputShape) #read image from file\n",
    "                image = img_to_array(image)\n",
    "                #Call the pyimagesearch() function\n",
    "                myStr=pyimagesearch(optValue.get(),image)\n",
    "                \n",
    "                \n",
    "                #2. Read image from file. This image format will be used to display the original image.\n",
    "                img_from_file=cv2.imread(fname,1)\n",
    "                \n",
    "                #split prediction result, so that it can be overlaid with image as text.\n",
    "                y0, dy = 15, 15 #yo is the initial y offset and dy is the subsequent offset\n",
    "                for i, line in enumerate(myStr.split('\\n')):\n",
    "                    y = y0 + i*dy\n",
    "                    cv2.putText(img_from_file, line, (0, y ), 1, 1, 2)\n",
    "\n",
    "                #display image with text\n",
    "                cv2.imshow('Object',img_from_file)\n",
    "\n",
    "            except: #give error message if file cannot be read                     \n",
    "                showerror(\"Open Source File\", \"Failed to read file\\n'%s'\" % fname)\n",
    "                \n",
    "            return       \n",
    "    \n",
    "    #if Video is selected, call the get_image_from_Video() function\n",
    "    else:\n",
    "        #print out prediction results\n",
    "        print(get_image_from_Video(optValue.get())) #change model to optValue.get() #need to troubleshoot\n",
    "\n",
    "#label    \n",
    "tk.Label(root, \n",
    "        text=\"\"\"Choose image source:\"\"\",\n",
    "        justify = tk.LEFT,\n",
    "        padx = 20).pack()\n",
    "\n",
    "#radio buttons\n",
    "rdbValue = tk.IntVar()\n",
    "options = [(\"Picture\"),(\"Video\")]\n",
    "\n",
    "for val, language in enumerate(options):\n",
    "    tk.Radiobutton(root, \n",
    "                  text=language,\n",
    "                  padx = 20, \n",
    "                  variable=rdbValue, \n",
    "                  value=val).pack(anchor=tk.W)\n",
    "\n",
    "#label\n",
    "tk.Label(root, \n",
    "        text=\"\"\"Choose pre-trained model:\"\"\",\n",
    "        justify = tk.LEFT,\n",
    "        padx = 20).pack()\n",
    "\n",
    "options = ['', 'vgg16', 'vgg19', 'resnet', 'inception', 'xception']\n",
    "optValue = tk.StringVar()\n",
    "optValue.set(options[1])\n",
    "\n",
    "optModels=tk.OptionMenu(root,optValue,\n",
    "              *options).pack(anchor=tk.CENTER)\n",
    "\n",
    "#button\n",
    "btnStart=tk.Button(root,\n",
    "          text=\"Start\",\n",
    "          padx = 80,\n",
    "         command=pressed_Start).pack(anchor=tk.W)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> 4. What else can we do with out-of-the-box pre-trained models (https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/)?   \n",
    "\n",
    "<br>\n",
    "\n",
    "a. Re-use architecture for a similar task (e.g., object recognition of medical images for disease diagnostics)    \n",
    "b. Add more classes and re-train to make it smarter:     \n",
    "  - https://www.tensorflow.org/hub/tutorials/image_retraining  \n",
    "  - https://becominghuman.ai/transfer-learning-retraining-inception-v3-for-custom-image-classification-2820f653c557      \n",
    "     \n",
    " \n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. What is happening under the hood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> 1. Imagenet: The origin of the pre-trained models  \n",
    "<br>\n",
    "    - The pre-trained models have been trained using a large number of images (over 14 million imaged from 20,000 categories) from a database called ImageNet.   \n",
    "\n",
    "    - The various pre-trained models that are built into the Keras library are some of the highest performing Convolutional Neural Networks on the ImageNet challenge over the past few years.       \n",
    "<br>\n",
    "**References**:  \n",
    "1. https://www.image-net.org  \n",
    "2. https://en.wikipedia.org/wiki/ImageNet  \n",
    "3. https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/  \n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> 2. Pre-trained model architecture\n",
    "<br>\n",
    "<br>\n",
    "E.g., the VGG16 model architecture (CNN):    \n",
    "\n",
    "To view the neural network architecture, first create the model object, and then call the summary() method. </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Command for viewing the neural network architectures\n",
    "\n",
    "#E.g., create VGG16 model object\n",
    "model = VGG16() \n",
    "\n",
    "#call out summary method\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> 3. Pre-trained models comparison   \n",
    "<br>\n",
    "https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "image/png": {
       "height": 400,
       "width": 600
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(i) Built-in pre-trained models in Keras\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "#https://keras.io/applications/#xception\n",
    "\n",
    "Image('keras-pretrained_ model.png', width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/EN10/KerasModels/master/Models.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://raw.githubusercontent.com/EN10/KerasModels/master/Models.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://blog.datumbox.com/wp-content/uploads/2018/04/keras-based-image-classifier-with-tensorflow-as-a-back-end-pre-trained-networks-v1-724x540.jpg\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='http://blog.datumbox.com/wp-content/uploads/2018/04/keras-based-image-classifier-with-tensorflow-as-a-back-end-pre-trained-networks-v1-724x540.jpg', width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> 4. Artificial intelligence - the big picture <ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The big picture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://data-bytes.in/wp-content/uploads/2017/08/AAEAAQAAAAAAAAgIAAAAJDVmNDM2NGJhLTk2OWItNDJiNy05OTYxLWRlYTEyNWNhNTU1Mg.png\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= 'http://data-bytes.in/wp-content/uploads/2017/08/AAEAAQAAAAAAAAgIAAAAJDVmNDM2NGJhLTk2OWItNDJiNy05OTYxLWRlYTEyNWNhNTU1Mg.png', width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"learning_schematics.png\" width=\"800\" height=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='learning_schematics.png', width=800, height=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The brain function versus the artificial neural network (ANN) model for supervised learning(ref.: Kirill Eremenko and Hadelin de Ponteves, Deep Learning A-Z™: Hands-On Artificial Neural Networks, Section 14-61, Udemy, 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four lobes of the human brain analogy to the artificial neural network:\n",
    "    - Frontal lobe (RNN: short-term memory)\n",
    "    - Parietal Lobe (spatial sense and navigation)\n",
    "    - Temporal Lobe (ANN: 'permanent' or long-term memory)\n",
    "    - Occipital Lobe (CNN: visual, recognition)\n",
    "    \n",
    "ref.: https://en.wikipedia.org/wiki/Lobes_of_the_brain#Parietal_lobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.humanbrainfacts.org/images/resource/human-brain-functions.jpg\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= 'https://www.humanbrainfacts.org/images/resource/human-brain-functions.jpg', width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Neurons Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> One neuron </center> | <center> Many Neurons </center>\n",
    ":-------------------------:|:-------------------------:\n",
    "![](https://qph.fs.quoracdn.net/main-qimg-e81753ca52a52e99869a97a969132c4e)|![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/300px-Colored_neural_network.svg.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN and RNN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1200/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CNN architecture\n",
    "\n",
    "Image(url= 'https://cdn-images-1.medium.com/max/1200/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg', width=600, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ytimg.com/vi/kMLl-TKaEnc/maxresdefault.jpg\" width=\"600\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RNN architecture: LSTM\n",
    "\n",
    "Image(url= 'https://i.ytimg.com/vi/kMLl-TKaEnc/maxresdefault.jpg',width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Resources for Further Study\n",
    "\n",
    "keywords: OpenCV, ImageNet, Neural Network, Machine Learning, Deep Learning  \n",
    "\n",
    "1. pyimagesearch: https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/\n",
    "2. learnopencv: https://www.learnopencv.com/about/\n",
    "3. packt: https://mapt.packtpub.com\n",
    "4. udemy: https://www.udemy.com\n",
    "5. machinelearningmastery: https://machinelearningmastery.com/products/\n",
    "6. AnalyticsVidhya: https://www.analyticsvidhya.com/\n",
    "7. Datacamp: https://www.datacamp.com\n",
    "8. Amazon kindle books\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
